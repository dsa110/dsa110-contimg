{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a5753f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-09 18:14:45 [INFO ] [MainThread] [root] CASA log file set to: /data/jfaber/dsa110-contimg/../logs/casa_20250509_181445.log\n",
      "2025-05-09 18:14:45 [INFO ] [MainThread] [root] Pipeline logging configured. Log file: /data/jfaber/dsa110-contimg/../logs/notebook_test_181445_20250509_181445.log\n",
      "2025-05-09 18:14:45 [INFO ] [MainThread] [root] Setup cell executed.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Notebook Setup Cell\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "\n",
    "# Astropy imports\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy.coordinates import SkyCoord, Angle, EarthLocation\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "# --- IMPORTANT: Adjust sys.path if needed ---\n",
    "# If your notebook is NOT in the same directory as the 'pipeline' folder,\n",
    "# add the parent directory to the path so Python can find the modules.\n",
    "# Example: If notebook is in '/data/jfaber/dsa110-contimg/' and pipeline\n",
    "# modules are in '/data/jfaber/dsa110-contimg/pipeline/', this should work.\n",
    "# If notebook is elsewhere, adjust the path accordingly.\n",
    "pipeline_parent_dir = '/data/jfaber/dsa110-contimg/' # Adjust if needed\n",
    "if pipeline_parent_dir not in sys.path:\n",
    "    sys.path.insert(0, pipeline_parent_dir)\n",
    "\n",
    "# Pipeline module imports\n",
    "try:\n",
    "    from pipeline import config_parser\n",
    "    from pipeline import pipeline_utils\n",
    "    from pipeline import ms_creation\n",
    "    from pipeline import calibration\n",
    "    from pipeline import skymodel\n",
    "    from pipeline import imaging\n",
    "    from pipeline import mosaicking\n",
    "    from pipeline import photometry\n",
    "    from pipeline import dsa110_utils # Needed for location\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Failed to import pipeline modules. Check sys.path.\")\n",
    "    print(f\"Current sys.path: {sys.path}\")\n",
    "    raise e\n",
    "\n",
    "# pyuvdata needed for reading header\n",
    "try:\n",
    "    from pyuvdata import UVData\n",
    "    pyuvdata_available = True\n",
    "except ImportError:\n",
    "     print(\"ERROR: pyuvdata is required to read HDF5 metadata.\")\n",
    "     pyuvdata_available = False # Script will likely fail later\n",
    "\n",
    "# --- Define Paths and Parameters ---\n",
    "# These replace command-line arguments\n",
    "CONFIG_PATH = 'config/pipeline_config.yaml' # Relative path from notebook location\n",
    "HDF5_DIR = '/data/incoming/'\n",
    "# Optional: Force a specific BPCAL name for testing, otherwise set to None\n",
    "BCAL_NAME_OVERRIDE = None\n",
    "VERBOSE_LOGGING = True # Set True for DEBUG level, False for INFO\n",
    "\n",
    "# --- Setup Logging ---\n",
    "# Load config minimally just to get log path\n",
    "try:\n",
    "    with open(CONFIG_PATH, 'r') as f:\n",
    "        temp_config = yaml.safe_load(f)\n",
    "    log_dir = temp_config.get('paths', {}).get('log_dir', 'logs')\n",
    "    # Resolve log_dir relative to pipeline parent dir if needed\n",
    "    if not os.path.isabs(log_dir):\n",
    "        log_dir = os.path.join(pipeline_parent_dir, log_dir)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_level = logging.DEBUG if VERBOSE_LOGGING else logging.INFO\n",
    "    # Setup logger (might print duplicate messages if run multiple times in notebook kernel)\n",
    "    logger = pipeline_utils.setup_logging(log_dir, config_name=f\"notebook_test_{datetime.now().strftime('%H%M%S')}\")\n",
    "    logger.setLevel(log_level)\n",
    "    # Suppress overly verbose CASA logs if desired\n",
    "    # from casatasks import casalog\n",
    "    # casalog.filter('INFO') # Filter to show only INFO and above for CASA tasks\n",
    "    logger.info(\"Setup cell executed.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR during setup: {e}\")\n",
    "    # Stop execution if setup fails\n",
    "    raise RuntimeError(\"Setup failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Cell: Helper Function Definitions\n",
    "\n",
    "# --- Copy the function definitions from test_pipeline_10min.py ---\n",
    "# get_obs_declination(config, hdf5_dir)\n",
    "# select_bcal_for_test(config, fixed_dec_deg, bcal_name_override=None)\n",
    "# calculate_next_transit(bcal_info, telescope_loc)\n",
    "# find_hdf5_chunks_around_time(config, hdf5_dir, target_time)\n",
    "# --- Make sure they use 'logging.' instead of 'logger.' if logger wasn't passed ---\n",
    "# Or modify them to accept logger as an argument\n",
    "\n",
    "# Example (showing one function, copy others similarly):\n",
    "def get_obs_declination(config, hdf5_dir):\n",
    "    \"\"\"Reads the fixed declination from an arbitrary HDF5 file's metadata.\"\"\"\n",
    "    if not pyuvdata_available: return None\n",
    "    logging.info(\"Attempting to determine observation declination from HDF5 metadata...\")\n",
    "    try:\n",
    "        pattern = os.path.join(hdf5_dir, \"20*_sb00.hdf5\")\n",
    "        hdf5_files = glob.glob(pattern)\n",
    "        if not hdf5_files:\n",
    "            raise FileNotFoundError(f\"No '*_sb00.hdf5' files found in {hdf5_dir} to read metadata.\")\n",
    "        uvd = UVData()\n",
    "        logging.debug(f\"Reading metadata from: {hdf5_files[0]}\")\n",
    "        uvd.read(hdf5_files[0], read_data=False)\n",
    "        fixed_dec_rad = uvd.extra_keywords['phase_center_dec']\n",
    "        fixed_dec_deg = np.rad2deg(fixed_dec_rad)\n",
    "        logging.info(f\"Determined observation Declination: {fixed_dec_deg:.4f} degrees\")\n",
    "        return fixed_dec_deg\n",
    "    except KeyError:\n",
    "        logging.error(f\"Metadata key 'phase_center_dec' not found in {hdf5_files[0]}. Cannot determine Dec.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to read HDF5 metadata to determine Declination: {e}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "# --- PASTE THE OTHER HELPER FUNCTIONS HERE ---\n",
    "# select_bcal_for_test(...)\n",
    "# calculate_next_transit(...)\n",
    "# find_hdf5_chunks_around_time(...)\n",
    "\n",
    "logging.info(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857806e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Cell: Load Config and Auto-Select Data\n",
    "\n",
    "config = config_parser.load_config(CONFIG_PATH)\n",
    "if not config:\n",
    "    raise ValueError(\"Failed to load configuration.\")\n",
    "\n",
    "# Ensure HDF5 handling is correct for test\n",
    "config['services']['hdf5_post_handle'] = 'none'\n",
    "logging.info(\"Ensuring HDF5 post_handle is set to 'none' for test.\")\n",
    "\n",
    "# --- Stage 0: Determine Dec, Select BPCAL, Find Chunks ---\n",
    "logging.info(\"--- Stage 0: Determine Dec, Select BPCAL, Find Chunks ---\")\n",
    "fixed_dec_deg = get_obs_declination(config, HDF5_DIR)\n",
    "if fixed_dec_deg is None: raise RuntimeError(\"Failed to get observation declination.\")\n",
    "config['calibration']['fixed_declination_deg'] = fixed_dec_deg # Update in memory\n",
    "\n",
    "selected_bcal_info = select_bcal_for_test(config, fixed_dec_deg, BCAL_NAME_OVERRIDE)\n",
    "if selected_bcal_info is None: raise RuntimeError(\"Failed to select BPCAL for test.\")\n",
    "\n",
    "transit_time = calculate_next_transit(selected_bcal_info, utils_dsa110.loc_dsa110)\n",
    "if transit_time is None: raise RuntimeError(\"Failed to calculate transit time.\")\n",
    "\n",
    "hdf5_files_1, hdf5_files_2, start_time_1, start_time_2 = find_hdf5_chunks_around_time(config, HDF5_DIR, transit_time)\n",
    "if not hdf5_files_1 or not hdf5_files_2: raise RuntimeError(\"Failed to find HDF5 chunks around transit time.\")\n",
    "\n",
    "ts1_str = start_time_1.strftime(\"%Y%m%dT%H%M%S\")\n",
    "ts2_str = start_time_2.strftime(\"%Y%m%dT%H%M%S\") # This is the transit chunk\n",
    "\n",
    "logging.info(f\"Selected HDF5 sets for processing: {ts1_str} and {ts2_str}\")\n",
    "\n",
    "# Store paths for next cell\n",
    "%store ts1_str ts2_str hdf5_files_1 hdf5_files_2 selected_bcal_info config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Cell: MS Creation\n",
    "%store -r ts1_str ts2_str hdf5_files_1 hdf5_files_2 selected_bcal_info config # Load variables\n",
    "\n",
    "logging.info(\"--- Stage 1: MS Creation ---\")\n",
    "ms_path_1 = ms_creation.process_hdf5_set(config, ts1_str, hdf5_files_1)\n",
    "ms_path_2 = ms_creation.process_hdf5_set(config, ts2_str, hdf5_files_2)\n",
    "\n",
    "if not ms_path_1 or not ms_path_2:\n",
    "    raise RuntimeError(\"MS Creation failed for one or both chunks.\")\n",
    "\n",
    "logging.info(f\"Created MS files: {os.path.basename(ms_path_1)}, {os.path.basename(ms_path_2)}\")\n",
    "ms_files_to_process = [ms_path_1, ms_path_2]\n",
    "\n",
    "# Store paths for next cell\n",
    "%store ms_files_to_process selected_bcal_info config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ea6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Cell: Calibration and Imaging\n",
    "%store -r ms_files_to_process selected_bcal_info config # Load variables\n",
    "\n",
    "logging.info(\"--- Stage 2: Calibration and Imaging ---\")\n",
    "processed_images = []\n",
    "processed_pbs = []\n",
    "block_mask_path = None\n",
    "template_image_path = None\n",
    "gcal_table_path = None\n",
    "cl_path_bcal = None\n",
    "paths_config = config['paths'] # Get paths config\n",
    "\n",
    "# 2a. Find latest BPCAL table\n",
    "try:\n",
    "    cal_tables_dir = paths_config['cal_tables_dir']\n",
    "    bcal_files = sorted(glob.glob(os.path.join(cal_tables_dir, \"*.bcal\")))\n",
    "    if not bcal_files: raise RuntimeError(f\"No BPCAL tables (*.bcal) found in {cal_tables_dir}.\")\n",
    "    latest_bcal_table = bcal_files[-1]\n",
    "    logging.info(f\"Using BPCAL table: {os.path.basename(latest_bcal_table)}\")\n",
    "except Exception as e:\n",
    "    logging.critical(f\"Failed to find BPCAL table: {e}. Aborting test.\")\n",
    "    raise e # Stop execution\n",
    "\n",
    "# 2b. Generate Calibrator Model & Gain Cal Table (using transit chunk only)\n",
    "try:\n",
    "    skymodels_dir = paths_config['skymodels_dir']\n",
    "    cl_bcal_filename = f\"bcal_sky_{selected_bcal_info['name']}_test.cl\" # Add suffix\n",
    "    cl_bcal_output_path = os.path.join(skymodels_dir, cl_bcal_filename)\n",
    "    cl_path_bcal, _ = skymodel.create_calibrator_component_list(config, selected_bcal_info, cl_bcal_output_path)\n",
    "    if not cl_path_bcal: raise RuntimeError(\"Failed to create BPCAL sky model.\")\n",
    "\n",
    "    # Use the second MS (transit chunk) for gain cal\n",
    "    ms_path_transit = ms_files_to_process[1]\n",
    "    ts_transit = os.path.basename(ms_path_transit).split('_')[1].replace('.ms', '')\n",
    "    logging.info(f\"Performing gain calibration on transit chunk: {os.path.basename(ms_path_transit)}\")\n",
    "    gcal_time_str = f\"bcal_test_{ts_transit}\"\n",
    "    gcal_table_path = calibration.perform_gain_calibration(config, [ms_path_transit], cl_path_bcal, gcal_time_str, solint='inf')\n",
    "    if not gcal_table_path: raise RuntimeError(\"Gain calibration on BPCAL failed.\")\n",
    "    logging.info(f\"Gain table generated: {os.path.basename(gcal_table_path)}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed during gain calibration setup stage: {e}\", exc_info=True)\n",
    "    logging.warning(\"Proceeding without gain calibration solutions.\")\n",
    "    gcal_table_path = []\n",
    "\n",
    "# 2c. Prepare Mask (using BPCAL model, defer creation until template exists)\n",
    "use_mask_config = config.get('imaging',{}).get('use_clean_mask', False)\n",
    "mask_output_path = None\n",
    "if use_mask_config and cl_path_bcal:\n",
    "    mask_output_path = os.path.join(skymodels_dir, f\"mask_bcal_test_{selected_bcal_info['name']}.mask\")\n",
    "    logging.info(f\"Will attempt to create mask: {mask_output_path}\")\n",
    "else:\n",
    "    logging.info(\"Masking disabled or BPCAL model missing, skipping mask.\")\n",
    "mask_created = False\n",
    "\n",
    "# 2d. Loop through MS files\n",
    "images_dir = paths_config['images_dir']\n",
    "for i, ms_path in enumerate(ms_files_to_process):\n",
    "    logging.info(f\"Processing MS {i+1}/{len(ms_files_to_process)}: {os.path.basename(ms_path)}\")\n",
    "    ms_base = os.path.splitext(os.path.basename(ms_path))[0]\n",
    "    image_base = os.path.join(images_dir, f\"{ms_base}_test\")\n",
    "\n",
    "    try:\n",
    "        if not calibration.flag_rfi(config, ms_path): raise RuntimeError(\"RFI Flagging failed.\")\n",
    "        if not calibration.flag_general(config, ms_path): raise RuntimeError(\"General Flagging failed.\")\n",
    "\n",
    "        gcal_list = [gcal_table_path] if gcal_table_path and isinstance(gcal_table_path, str) else []\n",
    "        if not calibration.apply_calibration(config, ms_path, latest_bcal_table, gcal_list):\n",
    "            raise RuntimeError(\"ApplyCal failed.\")\n",
    "\n",
    "        ms_to_image = ms_path\n",
    "        current_mask_path = None\n",
    "        if use_mask_config and mask_output_path:\n",
    "            if not mask_created:\n",
    "                if template_image_path:\n",
    "                    logging.info(f\"Creating block mask {mask_output_path} using template {template_image_path}\")\n",
    "                    if imaging.create_clean_mask(config, cl_path_bcal, template_image_path, mask_output_path):\n",
    "                        mask_created = True\n",
    "                    else: logging.warning(\"Failed to create mask. Proceeding without.\")\n",
    "                else: logging.debug(\"Template image not yet available for mask creation.\")\n",
    "            if mask_created: current_mask_path = mask_output_path\n",
    "\n",
    "        logging.info(\"Running tclean...\")\n",
    "        tclean_image_basename = imaging.run_tclean(config, ms_to_image, image_base, cl_path=None, mask_path=current_mask_path)\n",
    "\n",
    "        if tclean_image_basename:\n",
    "            img_path = f\"{tclean_image_basename}.image\"\n",
    "            pb_path = f\"{tclean_image_basename}.pb\"\n",
    "            if os.path.exists(img_path) and os.path.exists(pb_path):\n",
    "                processed_images.append(img_path); processed_pbs.append(pb_path)\n",
    "                logging.info(f\"Successfully imaged {ms_path}\")\n",
    "                if template_image_path is None: template_image_path = img_path\n",
    "            else: raise RuntimeError(f\"tclean image/pb missing for {tclean_image_basename}\")\n",
    "        else: raise RuntimeError(\"tclean failed.\")\n",
    "\n",
    "    except Exception as e_ms:\n",
    "        logging.error(f\"Failed processing MS {ms_path}: {e_ms}\", exc_info=True)\n",
    "        raise e_ms # Stop execution on failure\n",
    "\n",
    "# Store results for next cell\n",
    "%store processed_images processed_pbs config selected_bcal_info ts1_str ts2_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506999eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Cell: Mosaicking\n",
    "%store -r processed_images processed_pbs config selected_bcal_info ts1_str ts2_str # Load variables\n",
    "\n",
    "mosaic_img_path = None\n",
    "if len(processed_images) == 2:\n",
    "    logging.info(\"--- Stage 3: Mosaicking ---\")\n",
    "    # Use timestamps from original chunks for naming\n",
    "    mosaic_basename = f\"mosaic_test_{ts1_str}_{ts2_str}\"\n",
    "    try:\n",
    "        mosaic_img_path, _ = mosaicking.create_mosaic(config, processed_images, processed_pbs, mosaic_basename)\n",
    "        if not mosaic_img_path: raise RuntimeError(\"Mosaicking function returned None.\")\n",
    "        logging.info(f\"Mosaic created: {mosaic_img_path}\")\n",
    "        # Store for next cell\n",
    "        %store mosaic_img_path config selected_bcal_info ts1_str ts2_str\n",
    "    except Exception as e_mosaic:\n",
    "        logging.error(f\"Mosaicking failed: {e_mosaic}\", exc_info=True)\n",
    "        raise e_mosaic # Stop execution\n",
    "else:\n",
    "    raise RuntimeError(f\"Could not proceed to mosaicking: Only {len(processed_images)} images were created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb30f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Cell: Photometry\n",
    "%store -r mosaic_img_path config selected_bcal_info ts1_str ts2_str # Load variables\n",
    "\n",
    "if mosaic_img_path:\n",
    "    logging.info(\"--- Stage 4: Photometry ---\")\n",
    "    mosaic_fits_path = f\"{os.path.splitext(mosaic_img_path)[0]}.linmos.fits\"\n",
    "    if not os.path.exists(mosaic_fits_path):\n",
    "         logging.warning(f\"Mosaic FITS {mosaic_fits_path} not found, attempting export...\")\n",
    "         mosaic_fits_path = imaging.export_image_to_fits(config, mosaic_img_path, suffix='.linmos')\n",
    "\n",
    "    if mosaic_fits_path and os.path.exists(mosaic_fits_path):\n",
    "        logging.info(f\"Running photometry on mosaic: {mosaic_fits_path}\")\n",
    "        try:\n",
    "            targets, references = photometry.identify_sources(config, mosaic_fits_path)\n",
    "            # Convert to pandas DataFrames for easier handling below\n",
    "            phot_targets_df = pd.DataFrame(targets) if targets is not None else pd.DataFrame()\n",
    "            phot_references_df = pd.DataFrame(references) if references is not None else pd.DataFrame()\n",
    "\n",
    "            # Add BPCAL to targets list if not already there\n",
    "            if selected_bcal_info and selected_bcal_info['name'] not in phot_targets_df['name'].values:\n",
    "                 try:\n",
    "                      bcal_coord = SkyCoord(ra=selected_bcal_info['ra'], dec=selected_bcal_info['dec'], unit=(u.hourangle, u.deg), frame='icrs')\n",
    "                      with fits.open(mosaic_fits_path) as hdul: wcs = WCS(hdul[0].header).celestial\n",
    "                      xpix, ypix = wcs.world_to_pixel(bcal_coord)\n",
    "                      # Create row ensuring necessary columns exist\n",
    "                      bcal_row_data = {'name': selected_bcal_info['name'], 'source_id': selected_bcal_info['name'],\n",
    "                                      'RAJ2000': selected_bcal_info['ra'], 'DEC_J2000': selected_bcal_info['dec'],\n",
    "                                      'xpix': xpix, 'ypix': ypix}\n",
    "                      for col in phot_targets_df.columns:\n",
    "                           if col not in bcal_row_data: bcal_row_data[col] = np.nan\n",
    "                      phot_targets_df = pd.concat([phot_targets_df, pd.DataFrame([bcal_row_data])], ignore_index=True)\n",
    "                      logging.info(f\"Added BPCAL {selected_bcal_info['name']} to target list for photometry.\")\n",
    "                 except Exception as e_add: logging.warning(f\"Could not add BPCAL to target list: {e_add}\")\n",
    "\n",
    "\n",
    "            if not phot_targets_df.empty and not phot_references_df.empty:\n",
    "                phot_table = photometry.perform_aperture_photometry(config, mosaic_fits_path, phot_targets_df, phot_references_df)\n",
    "                if phot_table is not None:\n",
    "                    rel_flux_table = photometry.calculate_relative_fluxes(config, phot_table) # Assumes returns DF\n",
    "                    if rel_flux_table is not None:\n",
    "                        logging.info(\"Photometry successful. Relative flux results:\")\n",
    "                        print(\"\\n--- Relative Photometry Results ---\")\n",
    "                        # Display relevant columns using pandas display\n",
    "                        display_cols = ['source_id', 'relative_flux', 'relative_flux_error', 'median_reference_flux', 'reference_source_ids']\n",
    "                        # Ensure columns exist before displaying\n",
    "                        display_cols = [col for col in display_cols if col in rel_flux_table.columns]\n",
    "                        display(rel_flux_table[display_cols]) # Use IPython display\n",
    "\n",
    "                        # Save to a test CSV\n",
    "                        test_output_csv = os.path.join(config['paths']['photometry_dir'], f\"test_photometry_{ts1_str}_{ts2_str}.csv\")\n",
    "                        rel_flux_table.to_csv(test_output_csv, index=False, float_format='%.4f', na_rep='NaN')\n",
    "                        logging.info(f\"Saved test photometry results to: {test_output_csv}\")\n",
    "                    else: logging.error(\"Relative flux calculation failed.\")\n",
    "                else: logging.error(\"Aperture photometry failed.\")\n",
    "            elif phot_targets_df.empty: logging.warning(\"No target sources identified/valid for photometry.\")\n",
    "            else: logging.error(\"Reference source identification failed or references missing.\")\n",
    "        except Exception as e_phot: logging.error(f\"Photometry stage failed: {e_phot}\", exc_info=True)\n",
    "    else: logging.error(f\"Mosaic FITS file missing: {mosaic_fits_path}. Cannot run photometry.\")\n",
    "\n",
    "logging.info(\"--- Notebook Test Run Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726ff4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa_contimg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
