#!/usr/bin/env python3
"""Fix database schemas for DSA-110 backend"""
import os
import sqlite3
from pathlib import Path

STATE_DIR = Path("/data/dsa110-contimg/state")


def fix_queue_db():
    """Add location_type column to jobs and batch_jobs tables"""
    db_path = STATE_DIR / "queue.db"
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # Check if jobs table exists
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='jobs'")
    if not cursor.fetchone():
        print("Creating jobs table...")
        cursor.execute(
            """
            CREATE TABLE jobs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                type TEXT NOT NULL,
                status TEXT NOT NULL DEFAULT 'pending',
                ms_path TEXT,
                location_type TEXT,
                params TEXT,
                created_at REAL NOT NULL DEFAULT (strftime('%s', 'now')),
                started_at REAL,
                completed_at REAL,
                error_message TEXT,
                result TEXT
            )
        """
        )
        cursor.execute("CREATE INDEX idx_jobs_status ON jobs(status)")
        cursor.execute("CREATE INDEX idx_jobs_type ON jobs(type)")
        cursor.execute("CREATE INDEX idx_jobs_location ON jobs(location_type)")
    else:
        # Try to add location_type column if it doesn't exist
        try:
            cursor.execute("ALTER TABLE jobs ADD COLUMN location_type TEXT")
            print(":white_heavy_check_mark: Added location_type column to jobs table")
        except sqlite3.OperationalError as e:
            if "duplicate column name" in str(e):
                print(":check_mark: location_type column already exists in jobs")
            else:
                raise

    # Same for batch_jobs
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='batch_jobs'")
    if not cursor.fetchone():
        print("Creating batch_jobs table...")
        cursor.execute(
            """
            CREATE TABLE batch_jobs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                batch_type TEXT NOT NULL,
                status TEXT NOT NULL DEFAULT 'pending',
                location_type TEXT,
                item_count INTEGER DEFAULT 0,
                processed_count INTEGER DEFAULT 0,
                failed_count INTEGER DEFAULT 0,
                params TEXT,
                created_at REAL NOT NULL DEFAULT (strftime('%s', 'now')),
                started_at REAL,
                completed_at REAL
            )
        """
        )
        cursor.execute("CREATE INDEX idx_batch_status ON batch_jobs(status)")
    else:
        try:
            cursor.execute("ALTER TABLE batch_jobs ADD COLUMN location_type TEXT")
            print(":white_heavy_check_mark: Added location_type column to batch_jobs table")
        except sqlite3.OperationalError as e:
            if "duplicate column name" in str(e):
                print(":check_mark: location_type column already exists in batch_jobs")
            else:
                raise

    conn.commit()
    conn.close()
    print(":white_heavy_check_mark: queue.db fixed")


def init_pipeline_queue():
    """Initialize pipeline_queue.db if empty"""
    db_path = STATE_DIR / "pipeline_queue.db"
    if os.path.getsize(db_path) == 0:
        print("Initializing pipeline_queue.db...")
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        cursor.execute(
            """
            CREATE TABLE pipeline_executions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                job_type TEXT NOT NULL,
                status TEXT NOT NULL DEFAULT 'pending',
                started_at REAL,
                completed_at REAL,
                duration_seconds REAL,
                error_message TEXT,
                created_at REAL NOT NULL DEFAULT (strftime('%s', 'now'))
            )
        """
        )
        cursor.execute("CREATE INDEX idx_executions_status ON pipeline_executions(status)")
        cursor.execute("CREATE INDEX idx_executions_type ON pipeline_executions(job_type)")

        cursor.execute(
            """
            CREATE TABLE execution_stages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                execution_id INTEGER NOT NULL,
                stage_name TEXT NOT NULL,
                status TEXT NOT NULL DEFAULT 'pending',
                started_at REAL,
                completed_at REAL,
                duration_seconds REAL,
                attempt_count INTEGER DEFAULT 0,
                error_message TEXT,
                FOREIGN KEY (execution_id) REFERENCES pipeline_executions(id)
            )
        """
        )
        cursor.execute("CREATE INDEX idx_stages_execution ON execution_stages(execution_id)")
        cursor.execute("CREATE INDEX idx_stages_status ON execution_stages(status)")

        cursor.execute(
            """
            CREATE TABLE stage_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                stage_name TEXT NOT NULL,
                execution_count INTEGER DEFAULT 0,
                success_count INTEGER DEFAULT 0,
                failure_count INTEGER DEFAULT 0,
                total_duration_seconds REAL DEFAULT 0,
                last_execution_at REAL,
                created_at REAL NOT NULL DEFAULT (strftime('%s', 'now'))
            )
        """
        )
        cursor.execute("CREATE INDEX idx_metrics_stage ON stage_metrics(stage_name)")

        conn.commit()
        conn.close()
        print(":white_heavy_check_mark: pipeline_queue.db initialized")
    else:
        print(":check_mark: pipeline_queue.db already has data")


if __name__ == "__main__":
    print(":wrench: Fixing DSA-110 database schemas...\n")
    fix_queue_db()
    init_pipeline_queue()
    print("\n:white_heavy_check_mark: All database fixes applied!")
