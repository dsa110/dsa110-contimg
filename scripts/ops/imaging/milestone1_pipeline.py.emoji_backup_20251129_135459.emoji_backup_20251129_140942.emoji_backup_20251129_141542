#!/opt/miniforge/envs/casa6/bin/python
"""
Milestone 1: Create 60-minute science-quality mosaic using pipeline infrastructure

This script uses the existing pipeline infrastructure to:
1. Convert all subband groups in the 60-minute window
2. Calibrate each MS file using the pipeline
3. Image each MS file using the pipeline
4. Create PB-weighted mosaic from all images

All processing uses the tested pipeline components in src/dsa110_contimg/*
"""

import json
import logging
import signal
import sys
import time
from datetime import datetime
import os
from pathlib import Path
from typing import Any, Dict, List, Optional

import astropy.units as u
from astropy.time import Time

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from dsa110_contimg.calibration.catalogs import (get_calibrator_radec,
                                                 load_vla_catalog)
from dsa110_contimg.calibration.schedule import next_transit_time
from dsa110_contimg.pipeline.config import (CalibrationConfig,
                                            ConversionConfig, ImagingConfig,
                                            PathsConfig, PipelineConfig)
from dsa110_contimg.pipeline.context import PipelineContext
from dsa110_contimg.pipeline.resilience import RetryPolicy, RetryStrategy
from dsa110_contimg.pipeline.workflows import standard_imaging_workflow

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Global state for progress tracking
_progress_state: Dict[str, Any] = {
    "start_time": None,
    "last_heartbeat": None,
    "current_stage": None,
    "current_ms": None,
    "ms_index": 0,
    "total_ms": 0,
    "completed_ms": 0,
    "failed_ms": 0,
    "stage_start_time": None,
    "errors": [],
}


def update_progress(stage: Optional[str] = None, ms: Optional[str] = None, **kwargs):
    """Update progress file with current state."""
    global _progress_state
    
    _progress_state["last_heartbeat"] = datetime.utcnow().isoformat()
    if stage:
        _progress_state["current_stage"] = stage
        _progress_state["stage_start_time"] = time.time()
    if ms:
        _progress_state["current_ms"] = ms
    
    _progress_state.update(kwargs)
    
    try:
        PROGRESS_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(PROGRESS_FILE, 'w') as f:
            json.dump(_progress_state, f, indent=2)
    except Exception as e:
        logger.warning(f"Failed to update progress file: {e}")


def check_timeout() -> bool:
    """Check if current stage has exceeded timeout."""
    global _progress_state
    
    if _progress_state.get("stage_start_time"):
        elapsed = time.time() - _progress_state["stage_start_time"]
        if elapsed > STAGE_TIMEOUT:
            logger.error(
                f"Stage timeout: {_progress_state.get('current_stage')} "
                f"has been running for {elapsed:.0f}s (timeout: {STAGE_TIMEOUT}s)"
            )
            return True
    return False


def signal_handler(signum, frame):
    """Handle signals gracefully."""
    logger.warning(f"Received signal {signum}, updating progress and exiting...")
    update_progress(stage="interrupted")
    sys.exit(1)


# Register signal handlers
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# Configuration
CALIBRATOR_NAME = "0834+555"
TARGET_DATE = "2025-10-29"
MOSAIC_WINDOW_MINUTES = 60  # ±30 minutes around transit

# Progress tracking
PROGRESS_FILE = Path("/tmp/milestone1_progress.json")
HEARTBEAT_INTERVAL = 300  # 5 minutes
STAGE_TIMEOUT = 7200  # 2 hours per stage


def calculate_transit_time(calibrator_name: str, date: str) -> tuple[Time, Time, Time]:
    """Calculate peak transit time and 60-minute window."""
    logger.info(f"Calculating transit time for {calibrator_name} on {date}")
    
    catalog = load_vla_catalog()
    ra_deg, dec_deg = get_calibrator_radec(catalog, calibrator_name)
    logger.info(f"{calibrator_name}: RA={ra_deg:.6f}°, Dec={dec_deg:.6f}°")
    
    start = Time(f"{date}T00:00:00", format='isot')
    transit = next_transit_time(ra_deg, start.mjd)
    
    half_window = (MOSAIC_WINDOW_MINUTES / 2) * u.min
    start_time = transit - half_window
    end_time = transit + half_window
    
    logger.info(f"Peak transit: {transit.isot}")
    logger.info(f"60-minute window: {start_time.isot} to {end_time.isot}")
    
    return transit, start_time, end_time


def discover_ms_files(output_dir: Path) -> List[Path]:
    """Discover all MS files in output directory."""
    ms_files = []
    if output_dir.exists():
        for ms in output_dir.glob("*.ms"):
            if ms.is_dir():
                ms_files.append(ms)
    return sorted(ms_files)


def find_peak_transit_ms(ms_files: List[Path], transit_time: Time) -> Path:
    """Find the MS file closest to peak transit time."""
    min_diff = float('inf')
    peak_ms = None
    
    for ms_path in ms_files:
        # Extract time from MS filename (format: YYYY-MM-DDTHH:MM:SS.ms)
        try:
            ms_time_str = ms_path.stem
            ms_time = Time(ms_time_str, format='isot')
            diff = abs((ms_time - transit_time).to(u.min).value)
            if diff < min_diff:
                min_diff = diff
                peak_ms = ms_path
        except Exception as e:
            logger.warning(f"Could not parse time from {ms_path.name}: {e}")
            continue
    
    if peak_ms is None:
        raise RuntimeError("Could not find MS file closest to transit")
    
    logger.info(f"Peak transit MS: {peak_ms.name} (offset: {min_diff:.1f} min)")
    return peak_ms


def solve_calibration_on_ms(
    ms_path: Path,
    config: PipelineConfig,
    transit_time: Time,
) -> None:
    """Solve calibration on a single MS file (for peak transit MS only)."""
    logger.info(f"\n{'='*80}")
    logger.info(f"Solving calibration on: {ms_path.name}")
    logger.info(f"{'='*80}")
    update_progress(stage=f"calibration_solve_{ms_path.name}")
    
    context = PipelineContext(
        config=config,
        inputs={
            "ms_path": str(ms_path),
            "calibration_params": {
                "field": "0",  # Use field 0 (calibrator)
                "refant": config.calibration.default_refant,
                "model_source": "catalog",
                "calibrator_name": "0834+555",  # VLA calibrator
                "solve_delay": False,  # Skip K calibration
                "solve_bandpass": True,  # Solve bandpass (24-hour cadence)
                "solve_gains": True,  # Solve gains (hourly cadence)
                "gain_calmode": "p",  # Phase-only gains
                "gain_solint": config.calibration.cal_gain_solint,
                "bp_combine_field": True,
                "do_flagging": True,
                "flag_autocorr": True,  # Flag autocorrelations before solving
            },
        },
        outputs={
            "ms_path": str(ms_path),
        },
    )
    
    from dsa110_contimg.pipeline import stages_impl
    from dsa110_contimg.pipeline.orchestrator import (PipelineOrchestrator,
                                                      StageDefinition)
    
    retry_policy = RetryPolicy(
        max_attempts=2,
        strategy=RetryStrategy.EXPONENTIAL_BACKOFF,
        initial_delay=5.0,
        max_delay=30.0,
    )
    
    # Only solve calibration, don't apply or image
    stages = [
        StageDefinition(
            "calibrate_solve",
            stages_impl.CalibrationSolveStage(config),
            dependencies=[],
            retry_policy=retry_policy,
        ),
    ]
    
    orchestrator = PipelineOrchestrator(stages)
    result = orchestrator.execute(context)
    
    if result.status.value != "completed":
        error_msg = f"Calibration solve failed for {ms_path.name}: {result.status}"
        for stage_name, stage_result in result.stage_results.items():
            if stage_result.status.value == "failed" and stage_result.error:
                error_msg = f"Stage '{stage_name}' failed: {stage_result.error}"
                break
        update_progress(stage=f"calibration_solve_failed_{ms_path.name}", error=error_msg)
        raise RuntimeError(error_msg)
    
    logger.info(f":check_mark: Calibration solved successfully on {ms_path.name}")


def apply_calibration_to_ms(
    ms_path: Path,
    config: PipelineConfig,
) -> None:
    """Apply calibration to a single MS file."""
    logger.info(f"Applying calibration to: {ms_path.name}")
    update_progress(stage=f"calibration_apply_{ms_path.name}")
    
    context = PipelineContext(
        config=config,
        inputs={
            "ms_path": str(ms_path),
        },
        outputs={
            "ms_path": str(ms_path),
        },
    )
    
    from dsa110_contimg.pipeline import stages_impl
    from dsa110_contimg.pipeline.orchestrator import (PipelineOrchestrator,
                                                      StageDefinition)
    
    retry_policy = RetryPolicy(
        max_attempts=2,
        strategy=RetryStrategy.EXPONENTIAL_BACKOFF,
        initial_delay=5.0,
        max_delay=30.0,
    )
    
    # Only apply calibration (looks up tables from registry)
    stages = [
        StageDefinition(
            "calibrate",
            stages_impl.CalibrationStage(config),
            dependencies=[],
            retry_policy=retry_policy,
        ),
    ]
    
    orchestrator = PipelineOrchestrator(stages)
    result = orchestrator.execute(context)
    
    if result.status.value != "completed":
        error_msg = f"Calibration apply failed for {ms_path.name}: {result.status}"
        for stage_name, stage_result in result.stage_results.items():
            if stage_result.status.value == "failed" and stage_result.error:
                error_msg = f"Stage '{stage_name}' failed: {stage_result.error}"
                break
        update_progress(stage=f"calibration_apply_failed_{ms_path.name}", error=error_msg)
        raise RuntimeError(error_msg)


def image_ms(
    ms_path: Path,
    config: PipelineConfig,
) -> Path:
    """Image a single MS file."""
    logger.info(f"Imaging: {ms_path.name}")
    update_progress(stage=f"imaging_{ms_path.name}")
    
    context = PipelineContext(
        config=config,
        inputs={
            "ms_path": str(ms_path),
        },
        outputs={
            "ms_path": str(ms_path),
        },
    )
    
    from dsa110_contimg.pipeline import stages_impl
    from dsa110_contimg.pipeline.orchestrator import (PipelineOrchestrator,
                                                      StageDefinition)
    
    retry_policy = RetryPolicy(
        max_attempts=2,
        strategy=RetryStrategy.EXPONENTIAL_BACKOFF,
        initial_delay=5.0,
        max_delay=30.0,
    )
    
    # Only image
    stages = [
        StageDefinition(
            "image",
            stages_impl.ImagingStage(config),
            dependencies=[],
            retry_policy=retry_policy,
        ),
    ]
    
    orchestrator = PipelineOrchestrator(stages)
    result = orchestrator.execute(context)
    
    if result.status.value != "completed":
        error_msg = f"Imaging failed for {ms_path.name}: {result.status}"
        for stage_name, stage_result in result.stage_results.items():
            if stage_result.status.value == "failed" and stage_result.error:
                error_msg = f"Stage '{stage_name}' failed: {stage_result.error}"
                break
        update_progress(stage=f"imaging_failed_{ms_path.name}", error=error_msg)
        raise RuntimeError(error_msg)
    
    # Find the image path from outputs
    if "image_path" in result.context.outputs:
        image_path = Path(result.context.outputs["image_path"])
        # Look for PB-corrected version
        pbcor_path = Path(str(image_path).replace(".image", ".image.pbcor"))
        if pbcor_path.exists():
            return pbcor_path
        elif image_path.exists():
            return image_path
    
    # Fallback: construct expected path
    ms_name = ms_path.stem
    out_dir = ms_path.parent.parent / "images" / ms_path.parent.name
    pbcor_path = out_dir / f"{ms_name}.img.image.pbcor"
    if pbcor_path.exists():
        return pbcor_path
    
    raise RuntimeError(f"Could not find image for {ms_path.name}")


def main():
    """Main execution function."""
    global _progress_state
    
    _progress_state["start_time"] = datetime.utcnow().isoformat()
    update_progress(stage="initializing")
    
    # Step 1: Calculate transit time
    logger.info("="*80)
    logger.info("MILESTONE 1: 60-Minute Science-Quality Mosaic")
    logger.info(f"Calibrator: {CALIBRATOR_NAME}")
    logger.info(f"Date: {TARGET_DATE}")
    logger.info(f"Progress file: {PROGRESS_FILE}")
    logger.info("="*80)
    
    transit_time, start_time, end_time = calculate_transit_time(CALIBRATOR_NAME, TARGET_DATE)
    update_progress(
        stage="transit_calculated",
        transit_time=transit_time.isot,
        start_time=start_time.isot,
        end_time=end_time.isot,
    )
    
    # Step 2: Configure pipeline
    state_dir = Path(
        os.getenv("PIPELINE_STATE_DIR")
        or os.getenv("CONTIMG_STATE_DIR", "/data/dsa110-contimg/state")
    )
    config = PipelineConfig(
        paths=PathsConfig(
            input_dir=Path(os.getenv("CONTIMG_INPUT_DIR", "/data/incoming")),
            output_dir=Path(os.getenv("CONTIMG_OUTPUT_DIR", "/stage/dsa110-contimg/ms")),
            scratch_dir=Path(os.getenv("CONTIMG_SCRATCH_DIR", "/stage/dsa110-contimg")),
            state_dir=state_dir,
        ),
        conversion=ConversionConfig(
            writer="parallel-subband",
            max_workers=16,
            stage_to_tmpfs=True,
            expected_subbands=16,
        ),
        calibration=CalibrationConfig(
            cal_bp_minsnr=3.0,
            cal_gain_solint="inf",
            default_refant="103",
            auto_select_refant=True,
        ),
        imaging=ImagingConfig(
            field="",
            refant="103",
            gridder="wproject",
            wprojplanes=-1,
        ),
    )
    
    # Step 3: Convert all groups using ConversionStage
    logger.info("\n" + "="*80)
    logger.info("STEP 1: Converting Subband Groups to MS")
    logger.info("="*80)
    update_progress(stage="conversion")
    
    from dsa110_contimg.pipeline import stages_impl
    from dsa110_contimg.pipeline.orchestrator import (PipelineOrchestrator,
                                                      StageDefinition)

    # Use ConversionStage to convert (or discover existing) MS files
    conversion_context = PipelineContext(
        config=config,
        inputs={
            "start_time": start_time.isot,
            "end_time": end_time.isot,
        },
        outputs={},
    )
    
    conversion_stage = stages_impl.ConversionStage(config)
    retry_policy = RetryPolicy(
        max_attempts=2,
        strategy=RetryStrategy.EXPONENTIAL_BACKOFF,
        initial_delay=5.0,
        max_delay=30.0,
    )
    
    try:
        # Validate first
        is_valid, error_msg = conversion_stage.validate(conversion_context)
        if not is_valid:
            raise RuntimeError(f"Conversion validation failed: {error_msg}")
        
        # Execute conversion stage
        conversion_context = conversion_stage.execute(conversion_context)
        
        # Get all MS files from conversion stage output
        if "ms_paths" in conversion_context.outputs:
            ms_files = [Path(p) for p in conversion_context.outputs["ms_paths"]]
        else:
            # Fallback: discover manually if ms_paths not available
            ms_files = discover_ms_files(config.paths.output_dir)
        
        update_progress(stage="conversion_complete")
    except Exception as e:
        logger.error(f"Conversion failed: {e}", exc_info=True)
        _progress_state["errors"].append({"stage": "conversion", "error": str(e)})
        update_progress(stage="conversion_failed", error=str(e))
        return 1
    
    # Step 4: Verify MS files discovered
    if not ms_files:
        logger.error("No MS files found after conversion!")
        update_progress(stage="no_ms_files")
        return 1
    
    logger.info(f"\n:check_mark: Found {len(ms_files)} MS files")
    update_progress(
        stage="ms_discovered",
        total_ms=len(ms_files),
        ms_files=[str(m) for m in ms_files],
    )
    
    # Step 5: Find peak transit MS and solve calibration once
    logger.info("\n" + "="*80)
    logger.info("STEP 2: Solving Calibration on Peak Transit MS")
    logger.info("="*80)
    update_progress(stage="calibration_solve")
    
    try:
        peak_ms = find_peak_transit_ms(ms_files, transit_time)
        solve_calibration_on_ms(peak_ms, config, transit_time)
        logger.info(f":check_mark: Calibration solved on {peak_ms.name}")
    except Exception as e:
        logger.error(f":ballot_x: Calibration solve failed: {e}", exc_info=True)
        _progress_state["errors"].append({"stage": "calibration_solve", "error": str(e)})
        update_progress(stage="calibration_solve_failed", error=str(e))
        return 1
    
    # Step 6: Apply calibration to all MS files
    logger.info("\n" + "="*80)
    logger.info("STEP 3: Applying Calibration to All MS Files")
    logger.info("="*80)
    update_progress(stage="calibration_apply")
    
    calibrated_ms = []
    for i, ms_path in enumerate(ms_files, 1):
        if check_timeout():
            logger.error("Stage timeout detected, aborting")
            update_progress(stage="timeout", error="Stage timeout exceeded")
            return 1
        
        logger.info(f"\nApplying calibration to MS {i}/{len(ms_files)}: {ms_path.name}")
        update_progress(
            stage="calibration_apply",
            current_ms=str(ms_path),
            ms_index=i,
            completed_ms=len(calibrated_ms),
        )
        
        try:
            apply_calibration_to_ms(ms_path, config)
            calibrated_ms.append(ms_path)
            logger.info(f":check_mark: Calibration applied to {ms_path.name}")
        except Exception as e:
            logger.error(f":ballot_x: Failed to apply calibration to {ms_path.name}: {e}", exc_info=True)
            _progress_state["errors"].append({
                "stage": "calibration_apply",
                "ms": str(ms_path),
                "error": str(e),
            })
            continue
    
    if not calibrated_ms:
        logger.error("No MS files calibrated!")
        return 1
    
    logger.info(f"\n:check_mark: Calibrated {len(calibrated_ms)} MS files")
    
    # Step 7: Image all calibrated MS files
    logger.info("\n" + "="*80)
    logger.info("STEP 4: Imaging All Calibrated MS Files")
    logger.info("="*80)
    update_progress(stage="imaging")
    
    image_paths = []
    for i, ms_path in enumerate(calibrated_ms, 1):
        if check_timeout():
            logger.error("Stage timeout detected, aborting")
            update_progress(stage="timeout", error="Stage timeout exceeded")
            return 1
        
        logger.info(f"\nImaging MS {i}/{len(calibrated_ms)}: {ms_path.name}")
        update_progress(
            stage="imaging",
            current_ms=str(ms_path),
            ms_index=i,
            completed_ms=len(image_paths),
            failed_ms=_progress_state.get("failed_ms", 0),
        )
        
        try:
            image_path = image_ms(ms_path, config)
            image_paths.append(image_path)
            logger.info(f":check_mark: Successfully imaged: {image_path}")
            update_progress(completed_ms=len(image_paths))
        except Exception as e:
            logger.error(f":ballot_x: Failed to image {ms_path.name}: {e}", exc_info=True)
            _progress_state["failed_ms"] = _progress_state.get("failed_ms", 0) + 1
            _progress_state["errors"].append({
                "stage": "imaging",
                "ms": str(ms_path),
                "error": str(e),
            })
            update_progress(failed_ms=_progress_state["failed_ms"])
            continue
    
    if not image_paths:
        logger.error("No images produced!")
        return 1
    
    logger.info(f"\n:check_mark: Produced {len(image_paths)} images")
    
    # Step 8: Create mosaic
    logger.info("\n" + "="*80)
    logger.info("STEP 5: Creating Mosaic")
    logger.info("="*80)
    update_progress(stage="creating_mosaic")
    
    mosaic_name = f"{CALIBRATOR_NAME}_60min_{TARGET_DATE}"
    mosaic_dir = config.paths.scratch_dir / "mosaics"
    mosaic_dir.mkdir(parents=True, exist_ok=True)
    mosaic_path = mosaic_dir / f"{mosaic_name}.image"
    
    import argparse

    from dsa110_contimg.mosaic.cli import cmd_build
    
    try:
        args = argparse.Namespace(
            tiles=[str(p) for p in image_paths],
            output=str(mosaic_path),
            method="pbweighted",
            name=mosaic_name,
            validate=True,
            generate_metrics=True,
        )
        
        result = cmd_build(args)
        if result != 0:
            logger.error("Mosaic creation failed!")
            update_progress(stage="mosaic_failed", error="cmd_build returned non-zero")
            return 1
        
        update_progress(stage="completed", mosaic_path=str(mosaic_path))
        
        logger.info("\n" + "="*80)
        logger.info("MILESTONE 1 COMPLETE!")
        logger.info("="*80)
        logger.info(f"Mosaic: {mosaic_path}")
        logger.info(f"Calibrator: {CALIBRATOR_NAME}")
        logger.info(f"Transit: {transit_time.isot}")
        logger.info(f"Window: {start_time.isot} to {end_time.isot}")
        logger.info(f"MS files: {len(ms_files)}")
        logger.info(f"Images: {len(image_paths)}")
        logger.info(f"Progress file: {PROGRESS_FILE}")
        
        return 0
    except Exception as e:
        logger.error(f"Mosaic creation failed: {e}", exc_info=True)
        _progress_state["errors"].append({"stage": "mosaic", "error": str(e)})
        update_progress(stage="mosaic_failed", error=str(e))
        return 1


if __name__ == "__main__":
    sys.exit(main())
