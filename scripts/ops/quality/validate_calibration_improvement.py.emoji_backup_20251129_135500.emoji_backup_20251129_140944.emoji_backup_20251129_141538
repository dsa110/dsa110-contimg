#!/opt/miniforge/envs/casa6/bin/python
"""
Validate that calibration improves data quality.

This script:
1. Applies calibration to an MS
2. Compares DATA vs CORRECTED_DATA quality
3. Generates improvement metrics
4. Reports on calibration effectiveness
"""

import argparse
import sys
from pathlib import Path

import numpy as np

try:
    from casacore.tables import table
except ImportError:
    print("ERROR: casacore not available. Activate casa6 environment.")
    sys.exit(1)

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

try:
    from dsa110_contimg.calibration.applycal import apply_to_target
    from dsa110_contimg.utils.validation import validate_corrected_data_quality
except ImportError as e:
    print(f"ERROR: Could not import calibration modules: {e}")
    print("Make sure you're running from the repository root and src/ is in PYTHONPATH")
    sys.exit(1)


def analyze_data_quality(ms_path: str, column: str = "DATA", field: int = 0, sample_fraction: float = 0.1):
    """Analyze data quality for a specific column."""
    print(f"\n{'=' * 80}")
    print(f"Analyzing {column} Quality")
    print(f"{'=' * 80}")
    
    with table(ms_path, readonly=True) as tb:
        # Get field selection
        field_ids = tb.getcol("FIELD_ID")
        field_mask = field_ids == field
        
        # Get flags
        flags = tb.getcol("FLAG")
        flags_field = flags[field_mask]
        
        # Get data
        if column not in tb.colnames():
            print(f"ERROR: Column {column} not found in MS")
            return None
        
        data = tb.getcol(column)
        data_field = data[field_mask]
        
        # Sample data for efficiency
        nrows = data_field.shape[0]
        sample_size = max(1, int(nrows * sample_fraction))
        sample_indices = np.random.choice(nrows, sample_size, replace=False)
        
        data_sample = data_field[sample_indices]
        flags_sample = flags_field[sample_indices]
        
        # Analyze unflagged data
        unflagged = data_sample[~flags_sample]
        n_unflagged = np.size(unflagged)
        
        if n_unflagged == 0:
            print(f"WARNING: All sampled data is flagged")
            return None
        
        # Calculate metrics
        amplitudes = np.abs(unflagged)
        phases = np.angle(unflagged)
        
        metrics = {
            'column': column,
            'n_unflagged': n_unflagged,
            'n_total': np.size(data_sample),
            'fraction_unflagged': n_unflagged / np.size(data_sample),
            'median_amplitude': float(np.median(amplitudes)),
            'mean_amplitude': float(np.mean(amplitudes)),
            'std_amplitude': float(np.std(amplitudes)),
            'min_amplitude': float(np.min(amplitudes)),
            'max_amplitude': float(np.max(amplitudes)),
            'median_phase_deg': float(np.degrees(np.median(phases))),
            'phase_scatter_deg': float(np.degrees(np.std(phases))),
        }
        
        print(f"  Unflagged samples: {metrics['n_unflagged']}/{metrics['n_total']} ({metrics['fraction_unflagged']*100:.1f}%)")
        print(f"  Median amplitude: {metrics['median_amplitude']:.6f} Jy")
        print(f"  Amplitude scatter (std): {metrics['std_amplitude']:.6f} Jy")
        print(f"  Phase scatter: {metrics['phase_scatter_deg']:.2f}Â°")
        
        return metrics


def compare_data_vs_corrected(ms_path: str, field: int = 0):
    """Compare DATA vs CORRECTED_DATA quality."""
    print(f"\n{'=' * 80}")
    print(f"COMPARISON: DATA vs CORRECTED_DATA")
    print(f"{'=' * 80}")
    
    # Analyze DATA
    data_metrics = analyze_data_quality(ms_path, column="DATA", field=field)
    
    # Analyze CORRECTED_DATA
    corrected_metrics = analyze_data_quality(ms_path, column="CORRECTED_DATA", field=field)
    
    if data_metrics is None or corrected_metrics is None:
        print("ERROR: Could not analyze both columns")
        return None
    
    # Calculate improvements
    amp_improvement = corrected_metrics['std_amplitude'] / data_metrics['std_amplitude']
    phase_improvement = data_metrics['phase_scatter_deg'] / corrected_metrics['phase_scatter_deg']
    
    print(f"\n{'=' * 80}")
    print("IMPROVEMENT METRICS")
    print(f"{'=' * 80}")
    print(f"  Amplitude scatter reduction: {amp_improvement:.2f}x {'better' if amp_improvement < 1.0 else 'worse'}")
    print(f"  Phase scatter reduction: {phase_improvement:.2f}x {'better' if phase_improvement > 1.0 else 'worse'}")
    print(f"  Median amplitude change: {((corrected_metrics['median_amplitude'] - data_metrics['median_amplitude']) / data_metrics['median_amplitude'] * 100):+.1f}%")
    
    improvements = {
        'amplitude_scatter_factor': amp_improvement,
        'phase_scatter_factor': phase_improvement,
        'amplitude_change_percent': (corrected_metrics['median_amplitude'] - data_metrics['median_amplitude']) / data_metrics['median_amplitude'] * 100,
        'data_metrics': data_metrics,
        'corrected_metrics': corrected_metrics,
    }
    
    return improvements


def main():
    parser = argparse.ArgumentParser(
        description="Validate that calibration improves data quality"
    )
    parser.add_argument("ms_path", type=str, help="Path to Measurement Set")
    parser.add_argument("--caltables", type=str, nargs="+", required=True,
                       help="Calibration table paths (e.g., bpcal, gcal)")
    parser.add_argument("--field", type=int, default=0, help="Field to analyze (default: 0)")
    parser.add_argument("--apply", action="store_true", 
                       help="Apply calibration before validation (if not already applied)")
    parser.add_argument("--sample-fraction", type=float, default=0.1,
                       help="Fraction of data to sample for analysis (default: 0.1)")
    
    args = parser.parse_args()
    
    if not Path(args.ms_path).exists():
        print(f"ERROR: MS not found: {args.ms_path}")
        sys.exit(1)
    
    # Check if calibration tables exist
    missing = [ct for ct in args.caltables if not Path(ct).exists()]
    if missing:
        print(f"ERROR: Calibration tables not found: {missing}")
        sys.exit(1)
    
    # Apply calibration if requested
    if args.apply:
        print(f"\n{'=' * 80}")
        print("APPLYING CALIBRATION")
        print(f"{'=' * 80}")
        try:
            apply_to_target(args.ms_path, field=str(args.field), gaintables=args.caltables, verify=True)
            print(":check_mark: Calibration applied successfully")
        except Exception as e:
            print(f"ERROR: Failed to apply calibration: {e}")
            sys.exit(1)
    else:
        # Check if CORRECTED_DATA exists
        with table(args.ms_path, readonly=True) as tb:
            if "CORRECTED_DATA" not in tb.colnames():
                print("ERROR: CORRECTED_DATA column not found. Use --apply to apply calibration first.")
                sys.exit(1)
    
    # Compare DATA vs CORRECTED_DATA
    improvements = compare_data_vs_corrected(args.ms_path, field=args.field)
    
    if improvements is None:
        print("ERROR: Could not complete comparison")
        sys.exit(1)
    
    # Summary
    print(f"\n{'=' * 80}")
    print("VALIDATION SUMMARY")
    print(f"{'=' * 80}")
    
    if improvements['amplitude_scatter_factor'] < 1.0:
        print(":check_mark: Amplitude scatter improved")
    else:
        print(":warning_sign: Amplitude scatter increased (may indicate calibration issues)")
    
    if improvements['phase_scatter_factor'] > 1.0:
        print(":check_mark: Phase scatter improved")
    else:
        print(":warning_sign: Phase scatter increased (may indicate calibration issues)")
    
    print(f"\nCalibration appears to be: {'EFFECTIVE' if improvements['amplitude_scatter_factor'] < 1.0 and improvements['phase_scatter_factor'] > 1.0 else 'INEFFECTIVE or DEGRADING'}")
    
    return 0 if improvements['amplitude_scatter_factor'] < 1.0 and improvements['phase_scatter_factor'] > 1.0 else 1


if __name__ == "__main__":
    sys.exit(main())

